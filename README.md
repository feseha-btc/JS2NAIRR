# JS2NAIRR
JS2NAIRR_FAA: GPU-Accelerated Degenerate Fuzzy Oligo Finder
Project Overview
This repository hosts the code, data, and documentation for the JS2NAIRR_FAA project, which implements a high-performance, GPU-accelerated pipeline for identifying optimal degenerate oligonucleotide probes/primers within massive sequence datasets. The core engine leverages PyTorch and CUDA to parallelize the sequence matching process, drastically reducing execution time for bioinformatics analyses.

ðŸ“‚ Repository Structure
The project is organized into the following four primary directories:

1. Data
This folder holds all input, intermediate, and final processed data files necessary to run the pipeline.
Filename Description
- all_sequences.fasta The large, foundational FASTA file (e.g., a genome or large sequence collection) from which the master sequences are derived.
- query_oigos.fasta The set of oligonucleotides or target sequences used as queries for the pattern matching algorithm generated from the longest fasta sequence in all_sequences.fasta.
- master_oligos.fasta The master oligo file containing all fixed-length oligos generated from all_sequences.fasta, ready for GPU ingestion.
- oligo_hits.csv The raw output CSV from the GPU processing step, containing initial match counts.
- final_cluster_report.csv The final report generated by the pipeline, including calculated metrics like Percent Hit Value.

2. Scripts
This directory contains all the Python and shell scripts that orchestrate the pipeline and perform the core computations.
Filename Description
- geminiSimpleCluster_GPU.py 
Core Engine: The main Python script that handles data splitting, multi-GPU orchestration, and the tensor-based accelerated pattern matching algorithm. It can be internally adjusted to provide oligos with different lengths of 5â€™ or 3â€™ anchors as well as to skip from one-off overlap to two or three off overlaps.
- generate_oligo.py 
Preprocessing Utility: Creates fixed-length, overlapping oligonucleotide sequences from the large genomic input, preparing the master tensor for the GPU.
- run_workflow.sh 
The master shell script used to execute the three Python components sequentially, managing file I/O and dependencies.
- generate_report.py 
Post-Processing Utility: Calculates the Percent Hit Value metric from the raw match counts and prepares the final, formatted output.A supplementary shell script for generating the final human-readable summary report and applying filtering rules (e.g., >= 95% verified hits).

3. Documents
This folder is reserved for all non-code written materials related to the project, including your tutorial, publication manuscript, and internal notes.
â€¢ tutorial.md (or similar tutorial files)
â€¢ manuscript_draft.tex (for the final publication)
â€¢ flowchart.drawio (or other design diagrams)

4. miscellanewos
This folder can hold configuration files, license files, environment setup files, or any other items that do not fit into the primary categories.
â€¢ environment.yml or requirements.txt (for dependency management)
â€¢ LICENSE file
â€¢ Any temporary test data or logs.

ðŸš€ Getting Started
To run the pipeline, you will need Python 3 and PyTorch with CUDA support configured for your system.
1. Place your source sequences (genome_source.fasta) and query sequences (queries.fasta) into the Data folder.
2. Execute the main workflow script from the project root:
3. bash Scripts/run_workflow.sh
4. The final results will be available in the Data/final_cluster_report.csv.

