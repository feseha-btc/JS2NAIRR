# 1.1 Create project directory and enter it
mkdir JS2NAIRR_FAA
cd JS2NAIRR_FAA
# 1.2 Create required folders
mkdir -p data documents scripts tutorial
# 1.3 Create README.md (you can edit later)
cat > README.md <<'EOF'
# JS2NAIRR_FAA
Repository created by feseha-btc.
Folders:
- data
- documents
- scripts
- tutorial
Add project description here.
EOF
# 1.4 Create a simple .gitignore
cat > .gitignore <<'EOF'
# Python/General
__pycache__/
*.pyc
*.pyo
*.pyd
env/
venv/
.env
# System
.DS_Store
Thumbs.db
# Jupyter
.ipynb_checkpoints/
# Node
node_modules/
# Editor
.vscode/
.idea/
EOF

JS2NAIRR_FAA: GPU-Accelerated Degenerate Oligo Clustering

Project Overview

This repository hosts the code, data, and documentation for the JS2NAIRR_FAA project, which implements a high-performance, GPU-accelerated pipeline for identifying optimal degenerate oligonucleotide probes/primers within massive sequence datasets. The core engine leverages PyTorch and CUDA to parallelize the sequence matching process, drastically reducing execution time for bioinformatics analyses.

Repository Structure

The project is organized into the following four primary directories:

1. Data

This folder holds all input, intermediate, and final processed data files necessary to run the pipeline.

Filename Description

all_sequences.fasta The large, foundational FASTA file (e.g., a genome or large sequence collection) from which the master sequences are derived.

Query_oigos.fasta The set of oligonucleotides or target sequences used as queries for the pattern matching algorithm generated from the longest fasta sequence in all_sequences.fasta.

master_oligos.fasta The master oligo file containing all fixed-length oligos generated from all_sequences.fasta, ready for GPU ingestion.

oligo_hits.csv The raw output CSV from the GPU processing step, containing initial match counts.

final_cluster_report.csv The final report generated by the pipeline, including calculated metrics like Percent Hit Value.

2. Scripts

This directory contains all the Python and shell scripts that orchestrate the pipeline and perform the core computations.

Filename Description

geminiSimpleCluster_GPU.py Core Engine: The main Python script that handles data splitting, multi-GPU orchestration, and the tensor-based accelerated pattern matching algorithm. It can be internally adjusted to provide oligos with different lengths of 5’ or 3’ anchors as well as to skip from one-off overlap to two or three off overlaps.

generate_oligo.py Preprocessing Utility: Creates fixed-length, overlapping oligonucleotide sequences from the large genomic input, preparing the master tensor for the GPU.

run_workflow.sh The master shell script used to execute the three Python components sequentially, managing file I/O and dependencies.

generate_report.py Post-Processing Utility: Calculates the Percent Hit Value metric from the raw match counts and prepares the final, formatted output.A supplementary shell script for generating the final human-readable summary report and applying filtering rules (e.g., >= 95% verified hits).

3. Documents

This folder is reserved for all non-code written materials related to the project, including your tutorial, publication manuscript, and internal notes.

• tutorial.md (or similar tutorial files)

• manuscript_draft.tex (for the final publication)

• flowchart.drawio (or other design diagrams)

4. miscellanewos

This folder can hold configuration files, license files, environment setup files, or any other items that do not fit into the primary categories.

• environment.yml or requirements.txt (for dependency management)

• LICENSE file

• Any temporary test data or logs.

 Getting Started

To run the pipeline, you will need Python 3 and PyTorch with CUDA support configured for your system.

1. Place your source sequences (genome_source.fasta) and query sequences (queries.fasta) into the Data folder.

2. Execute the main workflow script from the project root:

3. bash Scripts/run_workflow.sh

4. The final results will be available in the Data/final_cluster_report.csv.


